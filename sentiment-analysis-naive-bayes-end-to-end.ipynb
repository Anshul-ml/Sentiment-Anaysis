{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\n\n# Record start time\nstart_time = time.time()\n\n\nimport nltk\nfrom os import getcwd\nimport numpy as np\nimport pandas as pd\nfrom nltk.corpus import twitter_samples\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer#reducing words to their base form.\nfrom nltk.tokenize import TweetTokenizer\nimport re\nimport string\nimport pdb\n\nnltk.download('stopwords')\nnltk.download('twitter_samples')\n\n\nend_time = time.time()\n\n# Calculate total time\ntotal_time = end_time - start_time\n\n# Print the total time\nprint(f\"Total time taken: {total_time} seconds\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-27T09:48:33.354786Z","iopub.execute_input":"2023-11-27T09:48:33.355220Z","iopub.status.idle":"2023-11-27T09:48:36.234063Z","shell.execute_reply.started":"2023-11-27T09:48:33.355182Z","shell.execute_reply":"2023-11-27T09:48:36.233210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Record start time\nstart_time = time.time()\n\n\n\n\n\n\n#FUNTIONS:\ndef process_tweet(tweet):\n    stemmer = PorterStemmer()\n    stopwords_english = stopwords.words('english')\n    tweet = re.sub(r'\\$\\w*|^RT[\\s]+|https?://[^\\s\\n\\r]+|#', '', tweet)\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n    tweet_tokens = tokenizer.tokenize(tweet)\n    tweets_clean = []\n    for word in tweet_tokens:\n        if(word not in stopwords_english and word not in string.punctuation):\n            stem_word = stemmer.stem(word)\n            tweets_clean.append(stem_word)\n    return tweets_clean\n    \ndef count_tweets(tweets, ys):\n    ys_list = np.squeeze(ys).tolist()\n    freqs = {}\n    for y,tweet in zip(ys_list, tweets):\n        for word in process_tweet(tweet):\n            pair = (word,y)\n            if pair in freqs:\n                freqs[pair] += 1\n            else:\n                freqs[pair] = 1\n    return freqs\n\ndef train_naive_bayes(freqs, train_x,train_y):\n    logprior = 0\n    loglikelihood = {}\n    vocab = set([pair[0] for pair in freqs.keys()])\n    V = len(vocab)\n    N_pos=0\n    N_neg=0\n    for pair in freqs.keys():\n        if pair[1]>0:\n            N_pos += 1\n        else:\n            N_neg += 1\n    \n    D = train_y.shape[0]\n    D_pos = train_y[train_y==1].shape[0]\n    D_neg = train_y[train_y==0].shape[0]\n    \n    logprior = np.log(D_pos) - np.log(D_neg)\n    \n    for word in vocab:\n        freqs_pos = freqs.get((word,1),0)\n        freqs_neg = freqs.get((word,0),0)\n        \n        p_w_pos = (freqs_pos + 1)/(N_pos + V)\n        p_w_neg = (freqs_neg + 1)/(N_neg + V)\n\n        loglikelihood[word] = np.log(p_w_pos) - np.log(p_w_neg)\n    \n    return logprior, loglikelihood\n\ndef predict_tweet(tweet):\n    logprior, loglikelihood = train_naive_bayes(freqs, train_x,train_y)\n    word_l = process_tweet(tweet)\n    p = 0\n    p += logprior\n    for word in word_l:\n        if word in loglikelihood:\n            p += loglikelihood[word]\n    return p\n\nall_positive_tweets = twitter_samples.strings('positive_tweets.json')\nall_negative_tweets = twitter_samples.strings('negative_tweets.json')\ntest_pos = all_positive_tweets[4000:]\ntrain_pos = all_positive_tweets[:4000]\ntest_neg = all_negative_tweets[4000:]\ntrain_neg = all_negative_tweets[:4000]\ntrain_x = train_pos + train_neg \ntest_x = test_pos + test_neg\ntrain_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\ntest_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n\nfreqs = count_tweets(train_x,train_y)\n\n\n#prediction\nmy_tweet = input(\"Enter a tweet: \")\n\np = predict_tweet(my_tweet)\nprint(p)\nif p>0.5999:\n    print(\"Positive Sentiment\")\nelif p>=-0.5999 and p<=0.5999:\n    print(\"Neutral Sentiment\")\nelse:\n    print(\"Negative Sentiment\")\n\n    \n    \nend_time = time.time()\n\n# Calculate total time\ntotal_time = end_time - start_time\n\n# Print the total time\nprint(f\"Total time taken: {total_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T09:57:22.250337Z","iopub.execute_input":"2023-11-27T09:57:22.250892Z","iopub.status.idle":"2023-11-27T09:57:29.333929Z","shell.execute_reply.started":"2023-11-27T09:57:22.250848Z","shell.execute_reply":"2023-11-27T09:57:29.332273Z"},"trusted":true},"execution_count":null,"outputs":[]}]}